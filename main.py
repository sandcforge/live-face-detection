import google.generativeai as genai
import time
import os
from tqdm import tqdm
import threading
from datetime import datetime, timedelta
import argparse
import re
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont

class GeminiVideoAnalyzer:
    def __init__(self, api_key, model_name='gemini-2.5-pro'):
        """åˆå§‹åŒ–Geminiè§†é¢‘åˆ†æå™¨"""
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(model_name)
        self.upload_progress = 0
        self.analysis_progress = 0
        self.current_status = "å‡†å¤‡ä¸­..."
        
    def _format_file_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes/1024:.1f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes/(1024*1024):.1f} MB"
        else:
            return f"{size_bytes/(1024*1024*1024):.1f} GB"
    
    def _get_file_info(self, file_path):
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        size = os.path.getsize(file_path)
        return {
            'name': os.path.basename(file_path),
            'size': size,
            'size_str': self._format_file_size(size)
        }
    
    def _upload_with_progress(self, file_path, file_type="video"):
        """å¸¦è¿›åº¦æ˜¾ç¤ºçš„æ–‡ä»¶ä¸Šä¼ """
        file_info = self._get_file_info(file_path)
        
        print(f"\nğŸ“ å¼€å§‹ä¸Šä¼ {file_type}æ–‡ä»¶...")
        print(f"   æ–‡ä»¶å: {file_info['name']}")
        print(f"   æ–‡ä»¶å¤§å°: {file_info['size_str']}")
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(
            total=100, 
            desc=f"ä¸Šä¼ {file_type}", 
            unit="%",
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'
        )
        
        # æ¨¡æ‹Ÿä¸Šä¼ è¿›åº¦ï¼ˆå› ä¸ºGoogle APIæ²¡æœ‰æä¾›çœŸå®è¿›åº¦å›è°ƒï¼‰
        upload_start = time.time()
        
        def simulate_upload_progress():
            for i in range(100):
                time.sleep(0.1)  # è°ƒæ•´è¿™ä¸ªå€¼æ¥æ¨¡æ‹Ÿä¸Šä¼ é€Ÿåº¦
                progress_bar.update(1)
                self.upload_progress = i + 1
        
        # å¯åŠ¨è¿›åº¦æ¨¡æ‹Ÿçº¿ç¨‹
        progress_thread = threading.Thread(target=simulate_upload_progress)
        progress_thread.start()
        
        try:
            # å®é™…ä¸Šä¼ æ–‡ä»¶
            uploaded_file = genai.upload_file(path=file_path)
            
            # ç­‰å¾…è¿›åº¦æ¡å®Œæˆ
            progress_thread.join()
            progress_bar.close()
            
            upload_time = time.time() - upload_start
            print(f"âœ… {file_type}ä¸Šä¼ å®Œæˆï¼è€—æ—¶: {upload_time:.1f}ç§’")
            print(f"   æ–‡ä»¶URI: {uploaded_file.uri}")
            
            return uploaded_file
            
        except Exception as e:
            progress_bar.close()
            print(f"âŒ {file_type}ä¸Šä¼ å¤±è´¥: {str(e)}")
            raise
    
    def _wait_for_file_processing(self, uploaded_file, file_type="video"):
        """ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆ"""
        print(f"\nâ³ ç­‰å¾…{file_type}æ–‡ä»¶å¤„ç†...")
        
        processing_start = time.time()
        spinner_chars = "|/-\\"
        spinner_idx = 0
        
        while uploaded_file.state.name == "PROCESSING":
            print(f"\rğŸ”„ {spinner_chars[spinner_idx]} æ–‡ä»¶å¤„ç†ä¸­... (å·²ç­‰å¾… {int(time.time() - processing_start)}ç§’)", end="")
            spinner_idx = (spinner_idx + 1) % len(spinner_chars)
            time.sleep(1)
            uploaded_file = genai.get_file(uploaded_file.name)
        
        print(f"\râœ… æ–‡ä»¶å¤„ç†å®Œæˆï¼æ€»è€—æ—¶: {int(time.time() - processing_start)}ç§’" + " " * 20)
        return uploaded_file
    
    def analyze_person_in_video(self, video_path, reference_photo_path):
        """å®Œæ•´çš„è§†é¢‘äººç‰©åˆ†ææµç¨‹"""
        
        print("ğŸ¬ Gemini 2.5 Pro è§†é¢‘äººç‰©è¯†åˆ«åˆ†æ")
        print("=" * 50)
        
        total_start_time = time.time()
        
        try:
            # æ­¥éª¤1ï¼šä¸Šä¼ å‚è€ƒç…§ç‰‡
            self.current_status = "ä¸Šä¼ å‚è€ƒç…§ç‰‡ä¸­..."
            reference_file = self._upload_with_progress(reference_photo_path, "å‚è€ƒç…§ç‰‡")
            
            # æ­¥éª¤2ï¼šä¸Šä¼ è§†é¢‘æ–‡ä»¶
            self.current_status = "ä¸Šä¼ è§†é¢‘æ–‡ä»¶ä¸­..."
            video_file = self._upload_with_progress(video_path, "è§†é¢‘")
            
            # æ­¥éª¤3ï¼šç­‰å¾…æ–‡ä»¶å¤„ç†
            self.current_status = "å¤„ç†å‚è€ƒç…§ç‰‡ä¸­..."
            reference_file = self._wait_for_file_processing(reference_file, "å‚è€ƒç…§ç‰‡")
            
            self.current_status = "å¤„ç†è§†é¢‘æ–‡ä»¶ä¸­..."
            video_file = self._wait_for_file_processing(video_file, "è§†é¢‘")
            
            # æ­¥éª¤4ï¼šæ„å»ºåˆ†ææç¤º
            self.current_status = "æ„å»ºåˆ†ææç¤ºä¸­..."
            print(f"\nğŸ“ æ„å»ºåˆ†ææç¤º...")
            
            prompt = f"""
            æˆ‘éœ€è¦ä½ è¯¦ç»†åˆ†æè¿™ä¸ªç›´æ’­è§†é¢‘ï¼Œåˆ¤æ–­å‚è€ƒç…§ç‰‡ä¸­çš„äººç‰©æ˜¯å¦ä»¥çœŸäººå½¢å¼å‡ºç°åœ¨è§†é¢‘ä¸­ã€‚

            **æ ¸å¿ƒä»»åŠ¡ï¼šåŸºäºç”Ÿç‰©ç‰¹å¾çš„èº«ä»½ç¡®è®¤ + æˆªå›¾è¯æ®æ”¯æ’‘**
            **é‡è¦ï¼šä»…å…³æ³¨ä¸å¯å˜çš„ç”Ÿç‰©ç‰¹å¾ï¼Œæ’é™¤æ‰€æœ‰å¯å˜å¤–åœ¨å› ç´ **
            **å¿…è¦ï¼šæ¯ä¸ªç»“è®ºéƒ½å¿…é¡»æä¾›æ—¶é—´æˆ³æˆªå›¾ä½œä¸ºå¯è§†åŒ–è¯æ®**

            **ç¬¬ä¸€æ­¥ï¼šå‚è€ƒç…§ç‰‡ç”Ÿç‰©ç‰¹å¾æå–**
            è¯·ä»…åˆ†æä»¥ä¸‹å›ºæœ‰ç‰¹å¾ï¼ˆå¿½ç•¥å‘å‹ã€æœè£…ã€çœ¼é•œã€é¥°å“ã€å¦†å®¹ç­‰ï¼‰ï¼š
            1. **éª¨éª¼ç»“æ„ç‰¹å¾**ï¼š
               - å¤´é¢…å½¢çŠ¶å’Œæ¯”ä¾‹ï¼ˆé•¿å®½æ¯”ã€å‰é¢é«˜åº¦ï¼‰
               - è„¸å‹è½®å»“ï¼ˆæ–¹å½¢/åœ†å½¢/æ¤­åœ†å½¢/å¿ƒå½¢ï¼‰
               - é¢§éª¨é«˜åº¦å’Œçªå‡ºç¨‹åº¦
               - ä¸‹é¢Œçº¿æ¡å’Œä¸‹å·´å½¢çŠ¶

            2. **äº”å®˜å›ºæœ‰ç‰¹å¾**ï¼š
               - é¼»æ¢å½¢çŠ¶ï¼ˆç›´/å¼¯æ›²ï¼‰ã€é¼»ç¿¼å®½åº¦ã€é¼»å¤´å½¢çŠ¶
               - å˜´å”‡åšåº¦æ¯”ä¾‹ã€å˜´è§’å½¢çŠ¶ã€äººä¸­æ·±åº¦
               - çœ‰éª¨ç»“æ„ã€çœ‰é—´è·ç¦»
               - è€³å»“å½¢çŠ¶å’Œè€³å‚ç‰¹å¾ï¼ˆå¦‚æœå¯è§ï¼‰

            3. **é¢éƒ¨æ¯”ä¾‹å…³ç³»**ï¼š
               - ä¸‰åº­äº”çœ¼æ¯”ä¾‹
               - çœ¼è·ä¸é¢å®½æ¯”ä¾‹
               - é¼»é•¿ä¸é¢é•¿æ¯”ä¾‹

            **ç¬¬äºŒæ­¥ï¼šè§†é¢‘æ´»ä½“æ£€æµ‹ä¸ç”Ÿç‰©ç‰¹å¾å¯¹æ¯”**
            é€æ®µåˆ†æè§†é¢‘æ—¶ï¼Œå¿…é¡»åŒæ—¶éªŒè¯ï¼š

            A. **æ´»ä½“çœŸå®æ€§æŒ‡æ ‡**ï¼š
               - è‡ªç„¶çš„é¢éƒ¨è¡¨æƒ…å˜åŒ–å’Œå¾®è¡¨æƒ…
               - çœ¨çœ¼é¢‘ç‡å’Œè‡ªç„¶ç¨‹åº¦
               - è¯´è¯æ—¶å£å‹ä¸å£°éŸ³çš„åŒæ­¥æ€§
               - å¤´éƒ¨çš„ä¸‰ç»´è½¬åŠ¨å’Œè§’åº¦å˜åŒ–
               - é¢éƒ¨è‚Œè‚‰çš„è‡ªç„¶è¿åŠ¨

            B. **é˜²ä¼ªæ£€æµ‹**ï¼š
               - æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¹³é¢ç…§ç‰‡ç‰¹å¾ï¼šè¾¹ç¼˜åå…‰ã€ä¸è‡ªç„¶çš„é˜´å½±
               - è§‚å¯Ÿäººç‰©ä¸ç¯å¢ƒçš„æ·±åº¦å…³ç³»æ˜¯å¦çœŸå®
               - éªŒè¯å…‰çº¿åœ¨é¢éƒ¨çš„è‡ªç„¶åå°„æ•ˆæœ
               - æ£€æµ‹æ˜¯å¦æœ‰å±å¹•æ˜¾ç¤ºç—•è¿¹ï¼ˆåƒç´ ç‚¹ã€åˆ·æ–°é¢‘ç‡ï¼‰

            C. **ç”Ÿç‰©ç‰¹å¾åŒ¹é…**ï¼š
               - å¯¹æ¯”ä¸Šè¿°æå–çš„éª¨éª¼ç»“æ„ç‰¹å¾
               - éªŒè¯äº”å®˜å›ºæœ‰å½¢çŠ¶æ˜¯å¦ä¸€è‡´
               - è®¡ç®—é¢éƒ¨æ¯”ä¾‹å…³ç³»çš„åŒ¹é…åº¦

            **ç¬¬ä¸‰æ­¥ï¼šè¯æ®æ”¶é›†ï¼ˆå¼ºåˆ¶è¦æ±‚ï¼‰**
            **é‡è¦ï¼šæ— è®ºç»“è®ºå¦‚ä½•ï¼Œéƒ½å¿…é¡»æä¾›æ—¶é—´æˆ³æˆªå›¾ä½œä¸ºè¯æ®**

            A. **å¦‚æœåˆ¤æ–­ä¸ºåŒä¸€äºº**ï¼š
               - æä¾›3-5ä¸ªæœ€ç›¸ä¼¼çš„æ—¶é—´æˆ³ï¼ˆæœ€æ¸…æ™°çš„æ­£é¢è§’åº¦ï¼‰
               - æ¯ä¸ªæ—¶é—´æˆ³è¯´æ˜è¯æ˜çš„å…·ä½“ç”Ÿç‰©ç‰¹å¾
               - ç”Ÿç‰©ç‰¹å¾ç›¸ä¼¼åº¦è¯„åˆ†ï¼ˆ1-10åˆ†ï¼‰
               - æ´»ä½“æ£€æµ‹ç½®ä¿¡åº¦ï¼ˆ1-10åˆ†ï¼‰

            B. **å¦‚æœåˆ¤æ–­ä¸ºä¸åŒäºº**ï¼š
               - æä¾›3-5ä¸ªè§†é¢‘ä¸­ä¸»è¦äººç‰©çš„ä»£è¡¨æ€§æ—¶é—´æˆ³
               - æ¯ä¸ªæ—¶é—´æˆ³è¯´æ˜ä¸å‚è€ƒç…§ç‰‡çš„å…³é”®å·®å¼‚
               - é‡ç‚¹å±•ç¤ºä¸åŒ¹é…çš„ç”Ÿç‰©ç‰¹å¾è¯æ®

            C. **å¦‚æœåˆ¤æ–­ä¸ç¡®å®š**ï¼š
               - æä¾›å¯¼è‡´ä¸ç¡®å®šçš„å…³é”®æ—¶é—´æˆ³
               - è¯´æ˜å“ªäº›ç‰¹å¾ç›¸ä¼¼ï¼Œå“ªäº›ç‰¹å¾ä¸åŒ
               - è§£é‡Šä¸ºä»€ä¹ˆæ— æ³•å¾—å‡ºæ˜ç¡®ç»“è®º

            **ç¬¬å››æ­¥ï¼šæ—¶é—´æˆ³è¯æ®è¯´æ˜ï¼ˆå¿…å¡«ï¼‰**
            å¯¹æ¯ä¸ªæä¾›çš„æ—¶é—´æˆ³ï¼Œå¿…é¡»è¯´æ˜ï¼š
            1. **é€‰æ‹©ç†ç”±**ï¼šä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ—¶é—´ç‚¹
            2. **ç‰¹å¾å±•ç¤º**ï¼šè¯¥æˆªå›¾æ˜¾ç¤ºçš„å…³é”®ç”Ÿç‰©ç‰¹å¾
            3. **å¯¹æ¯”ç»“è®º**ï¼šä¸å‚è€ƒç…§ç‰‡çš„å…·ä½“å¯¹æ¯”ç»“æœ
            4. **è¯æ®ä»·å€¼**ï¼šè¯¥æˆªå›¾å¯¹æœ€ç»ˆç»“è®ºçš„æ”¯æ’‘ä½œç”¨

            **ç¬¬äº”æ­¥ï¼šç»¼åˆåˆ¤æ–­**
            åŸºäºæˆªå›¾è¯æ®å¾—å‡ºæœ€ç»ˆç»“è®ºï¼š
            - æ˜ç¡®çš„åˆ¤æ–­ç»“è®ºï¼ˆæ˜¯/å¦/ä¸ç¡®å®šï¼‰
            - æ•´ä½“ç½®ä¿¡åº¦ï¼ˆ1-10åˆ†ï¼‰
            - å…³é”®è¯æ®æ€»ç»“

            **é˜²ä¼ªè­¦å‘Šçº§åˆ«**ï¼š
            - ä½é£é™©ï¼šè‡ªç„¶åŠ¨ä½œï¼ŒçœŸå®äº¤äº’
            - ä¸­é£é™©ï¼šéƒ¨åˆ†åŠ¨ä½œç•¥æ˜¾åƒµç¡¬
            - é«˜é£é™©ï¼šç–‘ä¼¼ç…§ç‰‡æˆ–å±å¹•æ˜¾ç¤º

            **è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
            åœ¨åˆ†æç»“è®ºåï¼Œè¯·å•ç‹¬åˆ—å‡ºï¼š
            è¯æ®æ—¶é—´æˆ³: [æ—¶é—´æˆ³1, æ—¶é—´æˆ³2, æ—¶é—´æˆ³3...]
            æ´»ä½“æ£€æµ‹è¯„åˆ†: X/10
            ç”Ÿç‰©ç‰¹å¾è¯„åˆ†: X/10
            ä¼ªé€ é£é™©è¯„åˆ†: X/10 (1-3åˆ†ä¸ºä½é£é™©ï¼Œ4-6åˆ†ä¸ºä¸­é£é™©ï¼Œ7-10åˆ†ä¸ºé«˜é£é™©)

            **æ—¶é—´æˆ³ç²¾åº¦è¦æ±‚ï¼š**
            - è¯·æä¾›å¸§çº§ç²¾ç¡®æ—¶é—´æˆ³ï¼Œæ ¼å¼ï¼šMM:SS.FF æˆ– HH:MM:SS.FF
            - å…¶ä¸­FFè¡¨ç¤ºè¯¥ç§’å†…çš„å¸§æ•°ï¼ˆä¾‹å¦‚ï¼š00:09.15 è¡¨ç¤ºç¬¬9ç§’çš„ç¬¬15å¸§ï¼‰
            - è¿™æ ·å¯ä»¥ç²¾ç¡®å®šä½åˆ°å…·ä½“å¸§ï¼Œæä¾›æœ€å‡†ç¡®çš„æˆªå›¾è¯æ®
            - å¦‚æœæ— æ³•ç¡®å®šå…·ä½“å¸§æ•°ï¼Œå¯ä½¿ç”¨ MM:SS.00 æ ¼å¼

            è¯·å¼€å§‹ä½ çš„ä¸“ä¸šç”Ÿç‰©è¯†åˆ«åˆ†æã€‚
            """
            
            # æ­¥éª¤5ï¼šå¼€å§‹AIåˆ†æ
            self.current_status = "AIåˆ†æä¸­..."
            print(f"\nğŸ¤– å¼€å§‹AIåˆ†æ...")
            print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
            
            analysis_start = time.time()
            
            # åˆ›å»ºåˆ†æè¿›åº¦æŒ‡ç¤ºå™¨
            analysis_progress = tqdm(
                total=100,
                desc="AIåˆ†æè¿›åº¦",
                bar_format='{l_bar}{bar}| {elapsed} | {desc}'
            )
            
            def simulate_analysis_progress():
                """æ¨¡æ‹Ÿåˆ†æè¿›åº¦"""
                # å‰30%è¾ƒå¿«
                for i in range(30):
                    time.sleep(2)
                    analysis_progress.update(1)
                
                # ä¸­é—´40%è¾ƒæ…¢ï¼ˆå®é™…åˆ†æé˜¶æ®µï¼‰
                for i in range(40):
                    time.sleep(5)
                    analysis_progress.update(1)
                
                # æœ€å30%é€æ¸å®Œæˆ
                for i in range(30):
                    time.sleep(3)
                    analysis_progress.update(1)
            
            # å¯åŠ¨è¿›åº¦æ¨¡æ‹Ÿ
            progress_thread = threading.Thread(target=simulate_analysis_progress)
            progress_thread.start()
            
            # å®é™…APIè°ƒç”¨
            response = self.model.generate_content([
                prompt,
                reference_file,
                video_file
            ])

            # è·å–tokenä½¿ç”¨ç»Ÿè®¡
            token_count = response.usage_metadata if hasattr(response, 'usage_metadata') else None
            
            # ç­‰å¾…è¿›åº¦æ¡å®Œæˆ
            progress_thread.join()
            analysis_progress.close()
            
            analysis_time = time.time() - analysis_start
            total_time = time.time() - total_start_time
            
            # æ­¥éª¤6ï¼šæ˜¾ç¤ºç»“æœ
            print(f"\nâœ… åˆ†æå®Œæˆï¼")
            print(f"   åˆ†æè€—æ—¶: {analysis_time/60:.1f}åˆ†é’Ÿ")
            print(f"   æ€»è€—æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")

            # æ˜¾ç¤ºtokenä½¿ç”¨ç»Ÿè®¡
            if token_count:
                print(f"\nğŸ“Š Tokenä½¿ç”¨ç»Ÿè®¡:")
                print(f"   è¾“å…¥token: {token_count.prompt_token_count:,}")
                print(f"   è¾“å‡ºtoken: {token_count.candidates_token_count:,}")
                print(f"   æ€»token: {token_count.total_token_count:,}")

            print("\n" + "=" * 50)
            print("ğŸ“Š åˆ†æç»“æœ:")
            print("=" * 50)
            print(response.text)

            # æå–åˆ†ææ•°æ®å¹¶ç”Ÿæˆè¯æ®æˆªå›¾
            analysis_data = self._extract_analysis_data_from_response(response.text)
            timestamps = analysis_data['timestamps']
            screenshot_files = []
            comparison_file = None

            # æ˜¾ç¤ºè¯„åˆ†ä¿¡æ¯
            if any([analysis_data['liveness_score'], analysis_data['biometric_score'], analysis_data['spoofing_risk_score']]):
                print(f"\nğŸ“Š ä¸“ä¸šè¯„åˆ†ç»“æœ:")
                if analysis_data['liveness_score'] is not None:
                    score_emoji = "âœ…" if analysis_data['liveness_score'] >= 8 else "âš ï¸" if analysis_data['liveness_score'] >= 6 else "âŒ"
                    print(f"   {score_emoji} æ´»ä½“æ£€æµ‹è¯„åˆ†: {analysis_data['liveness_score']}/10")
                if analysis_data['biometric_score'] is not None:
                    score_emoji = "âœ…" if analysis_data['biometric_score'] >= 8 else "âš ï¸" if analysis_data['biometric_score'] >= 6 else "âŒ"
                    print(f"   {score_emoji} ç”Ÿç‰©ç‰¹å¾è¯„åˆ†: {analysis_data['biometric_score']}/10")
                if analysis_data['spoofing_risk_score'] is not None:
                    if analysis_data['spoofing_risk_score'] <= 3:
                        risk_emoji = "ğŸŸ¢"
                        risk_level = "ä½é£é™©"
                    elif analysis_data['spoofing_risk_score'] <= 6:
                        risk_emoji = "ğŸŸ¡"
                        risk_level = "ä¸­é£é™©"
                    else:
                        risk_emoji = "ğŸ”´"
                        risk_level = "é«˜é£é™©"
                    print(f"   {risk_emoji} ä¼ªé€ é£é™©è¯„åˆ†: {analysis_data['spoofing_risk_score']}/10 ({risk_level})")

            if timestamps:
                screenshot_files = self._extract_video_frames(video_path, timestamps)
                if screenshot_files:
                    print(f"\nğŸ“· è¯æ®æˆªå›¾å·²ä¿å­˜:")
                    for file in screenshot_files:
                        print(f"   ğŸ–¼ï¸  {file}")

                    # ç”Ÿæˆå¯¹æ¯”å›¾
                    comparison_file = self._create_comparison_image(reference_photo_path, screenshot_files)
                    if comparison_file:
                        print(f"   ğŸ–¼ï¸  {comparison_file}")

            # æ¸…ç†ä¸Šä¼ çš„æ–‡ä»¶
            self._cleanup_files([reference_file, video_file])
            
            return {
                'success': True,
                'analysis': response.text,
                'analysis_time': analysis_time,
                'total_time': total_time,
                'token_usage': {
                    'prompt_tokens': token_count.prompt_token_count if token_count else 0,
                    'output_tokens': token_count.candidates_token_count if token_count else 0,
                    'total_tokens': token_count.total_token_count if token_count else 0
                } if token_count else None,
                'timestamps': timestamps,
                'screenshot_files': screenshot_files,
                'comparison_file': comparison_file,
                'liveness_score': analysis_data['liveness_score'],
                'biometric_score': analysis_data['biometric_score'],
                'spoofing_risk_score': analysis_data['spoofing_risk_score']
            }
            
        except Exception as e:
            print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _extract_analysis_data_from_response(self, response_text):
        """ä»AIå“åº”ä¸­æå–æ—¶é—´æˆ³å’Œè¯„åˆ†ä¿¡æ¯"""
        result = {
            'timestamps': [],
            'liveness_score': None,
            'biometric_score': None,
            'spoofing_risk_score': None
        }

        # æå–æ—¶é—´æˆ³ï¼ˆæ”¯æŒä¸­è‹±æ–‡æ ¼å¼å’Œå¸§ç²¾åº¦ï¼‰
        timestamp_patterns = [
            r'è¯æ®æ—¶é—´æˆ³:\s*\[(.*?)\]',
            r'EVIDENCE_TIMESTAMPS:\s*\[(.*?)\]'
        ]
        for pattern in timestamp_patterns:
            timestamp_match = re.search(pattern, response_text, re.IGNORECASE)
            if timestamp_match:
                timestamps_str = timestamp_match.group(1)
                # æ”¯æŒå¸§ç²¾åº¦æ ¼å¼ï¼šMM:SS.FF æˆ– HH:MM:SS.FFï¼Œä»¥åŠæ—§æ ¼å¼
                time_pattern = r'(\d{1,2}:\d{2}(?::\d{2})?(?:\.\d{1,2})?)'
                result['timestamps'] = re.findall(time_pattern, timestamps_str)
                break

        # æå–æ´»ä½“æ£€æµ‹è¯„åˆ†ï¼ˆæ”¯æŒä¸­è‹±æ–‡æ ¼å¼ï¼‰
        liveness_patterns = [
            r'æ´»ä½“æ£€æµ‹è¯„åˆ†:\s*(\d+)/10',
            r'LIVENESS_SCORE:\s*(\d+)/10'
        ]
        for pattern in liveness_patterns:
            liveness_match = re.search(pattern, response_text, re.IGNORECASE)
            if liveness_match:
                result['liveness_score'] = int(liveness_match.group(1))
                break

        # æå–ç”Ÿç‰©ç‰¹å¾è¯„åˆ†ï¼ˆæ”¯æŒä¸­è‹±æ–‡æ ¼å¼ï¼‰
        biometric_patterns = [
            r'ç”Ÿç‰©ç‰¹å¾è¯„åˆ†:\s*(\d+)/10',
            r'BIOMETRIC_SCORE:\s*(\d+)/10'
        ]
        for pattern in biometric_patterns:
            biometric_match = re.search(pattern, response_text, re.IGNORECASE)
            if biometric_match:
                result['biometric_score'] = int(biometric_match.group(1))
                break

        # æå–ä¼ªé€ é£é™©è¯„åˆ†ï¼ˆæ–°çš„æ•°å­—æ ¼å¼ï¼‰
        spoofing_score_pattern = r'ä¼ªé€ é£é™©è¯„åˆ†:\s*(\d+)/10'
        spoofing_score_match = re.search(spoofing_score_pattern, response_text, re.IGNORECASE)
        if spoofing_score_match:
            result['spoofing_risk_score'] = int(spoofing_score_match.group(1))

        return result

    def _convert_timestamp_to_frame_info(self, timestamp, fps):
        """å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºå¸§ä¿¡æ¯"""
        # åˆ†ç¦»æ—¶é—´å’Œå¸§æ•°
        if '.' in timestamp:
            time_part, frame_part = timestamp.split('.')
            frame_offset = int(frame_part)
        else:
            time_part = timestamp
            frame_offset = 0

        # è§£ææ—¶é—´éƒ¨åˆ†
        parts = time_part.split(':')
        if len(parts) == 2:  # MM:SSæ ¼å¼
            minutes, seconds = int(parts[0]), int(parts[1])
            total_seconds = minutes * 60 + seconds
        elif len(parts) == 3:  # HH:MM:SSæ ¼å¼
            hours, minutes, seconds = int(parts[0]), int(parts[1]), int(parts[2])
            total_seconds = hours * 3600 + minutes * 60 + seconds
        else:
            total_seconds = 0

        # è®¡ç®—ç²¾ç¡®å¸§å·
        base_frame = int(total_seconds * fps)
        exact_frame = base_frame + frame_offset

        return {
            'total_seconds': total_seconds,
            'frame_offset': frame_offset,
            'exact_frame': exact_frame,
            'timestamp_with_frame': f"{time_part}.{frame_offset:02d}"
        }

    def _convert_timestamp_to_seconds(self, timestamp):
        """å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºç§’æ•°ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        # åˆ†ç¦»æ—¶é—´å’Œå¸§æ•°
        if '.' in timestamp:
            time_part, _ = timestamp.split('.')
        else:
            time_part = timestamp

        parts = time_part.split(':')
        if len(parts) == 2:  # MM:SSæ ¼å¼
            minutes, seconds = int(parts[0]), int(parts[1])
            return minutes * 60 + seconds
        elif len(parts) == 3:  # HH:MM:SSæ ¼å¼
            hours, minutes, seconds = int(parts[0]), int(parts[1]), int(parts[2])
            return hours * 3600 + minutes * 60 + seconds
        return 0

    def _extract_video_frames(self, video_path, timestamps, output_dir="screenshots"):
        """æ ¹æ®æ—¶é—´æˆ³æå–è§†é¢‘å¸§ï¼ˆæ”¯æŒå¸§çº§ç²¾åº¦ï¼‰"""
        if not timestamps:
            return []

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        print(f"\nğŸ“¸ æå–è¯æ®æˆªå›¾...")
        print(f"   ç›®æ ‡æ—¶é—´æˆ³: {timestamps}")

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return []

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        extracted_files = []

        print(f"   è§†é¢‘ä¿¡æ¯: {fps:.2f} FPS, æ€»å¸§æ•°: {total_frames}")

        for i, timestamp in enumerate(timestamps):
            # è·å–ç²¾ç¡®å¸§ä¿¡æ¯
            frame_info = self._convert_timestamp_to_frame_info(timestamp, fps)
            exact_frame = frame_info['exact_frame']

            # ç¡®ä¿å¸§å·åœ¨æœ‰æ•ˆèŒƒå›´å†…
            if exact_frame >= total_frames:
                exact_frame = total_frames - 1
                print(f"   âš ï¸  æ—¶é—´æˆ³ {timestamp} è¶…å‡ºè§†é¢‘èŒƒå›´ï¼Œä½¿ç”¨æœ€åä¸€å¸§")

            # ç²¾ç¡®å®šä½åˆ°æŒ‡å®šå¸§
            cap.set(cv2.CAP_PROP_POS_FRAMES, exact_frame)
            ret, frame = cap.read()

            if ret:
                # éªŒè¯å®é™…æå–çš„å¸§å·
                actual_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES)) - 1

                # ç”Ÿæˆæ–‡ä»¶åï¼ˆæ›¿æ¢ç‰¹æ®Šå­—ç¬¦ï¼‰
                safe_timestamp = timestamp.replace(':', '-').replace('.', '_')
                filename = f"evidence_{i+1}_{safe_timestamp}_frame{exact_frame}.jpg"
                filepath = os.path.join(output_dir, filename)
                cv2.imwrite(filepath, frame)
                extracted_files.append(filepath)

                print(f"   âœ… å·²æå–: {filename}")
                print(f"       ç›®æ ‡æ—¶é—´æˆ³: {timestamp} (ç¬¬{exact_frame}å¸§)")
                print(f"       å®é™…æå–å¸§: ç¬¬{actual_frame}å¸§")
                if abs(actual_frame - exact_frame) > 1:
                    print(f"       âš ï¸  å¸§åç§»: {actual_frame - exact_frame}å¸§")
            else:
                print(f"   âŒ æå–å¤±è´¥: æ—¶é—´æˆ³ {timestamp} (ç¬¬{exact_frame}å¸§)")

        cap.release()
        return extracted_files

    def _create_comparison_image(self, reference_photo_path, screenshot_files, output_dir="screenshots"):
        """åˆ›å»ºå‚è€ƒç…§ç‰‡ä¸æˆªå›¾çš„å¯¹æ¯”å›¾"""
        if not screenshot_files:
            return None

        try:
            # è¯»å–å‚è€ƒç…§ç‰‡
            ref_img = Image.open(reference_photo_path)

            # è®¾ç½®å›¾ç‰‡å°ºå¯¸
            img_width = 300
            img_height = 300

            # è°ƒæ•´å‚è€ƒç…§ç‰‡å¤§å°
            ref_img = ref_img.resize((img_width, img_height), Image.Resampling.LANCZOS)

            # è®¡ç®—æ€»ç”»å¸ƒå°ºå¯¸
            cols = min(4, len(screenshot_files) + 1)  # æœ€å¤š4åˆ—
            rows = (len(screenshot_files) + 1 + cols - 1) // cols  # è®¡ç®—æ‰€éœ€è¡Œæ•°

            canvas_width = cols * img_width + (cols + 1) * 20  # é—´è·
            canvas_height = rows * (img_height + 40) + 40  # æ ‡é¢˜ç©ºé—´

            # åˆ›å»ºç”»å¸ƒ
            canvas = Image.new('RGB', (canvas_width, canvas_height), 'white')
            draw = ImageDraw.Draw(canvas)

            # å°è¯•åŠ è½½å­—ä½“
            try:
                font = ImageFont.truetype("Arial.ttf", 16)
            except:
                font = ImageFont.load_default()

            # æ”¾ç½®å‚è€ƒç…§ç‰‡
            canvas.paste(ref_img, (20, 40))
            draw.text((20, 10), "å‚è€ƒç…§ç‰‡", fill='black', font=font)

            # æ”¾ç½®æˆªå›¾
            for i, screenshot_file in enumerate(screenshot_files):
                try:
                    screenshot = Image.open(screenshot_file)
                    screenshot = screenshot.resize((img_width, img_height), Image.Resampling.LANCZOS)

                    # è®¡ç®—ä½ç½®
                    col = (i + 1) % cols
                    row = (i + 1) // cols
                    if col == 0:
                        col = cols
                        row -= 1

                    x = col * (img_width + 20)
                    y = row * (img_height + 40) + 40

                    canvas.paste(screenshot, (x, y))

                    # æ·»åŠ æ—¶é—´æˆ³å’Œå¸§å·æ ‡ç­¾
                    filename = os.path.basename(screenshot_file)
                    # è§£ææ–°æ ¼å¼çš„æ–‡ä»¶å: evidence_1_00-09_15_frame15.jpg
                    parts = filename.split('_')
                    if len(parts) >= 4 and 'frame' in parts[-1]:
                        # æ–°æ ¼å¼: æœ‰å¸§å·ä¿¡æ¯
                        timestamp_part = '_'.join(parts[2:-1])  # 00-09_15
                        frame_part = parts[-1].replace('.jpg', '')  # frame15
                        timestamp = timestamp_part.replace('-', ':').replace('_', '.')  # 00:09.15
                        frame_num = frame_part.replace('frame', '')
                        label = f"æ—¶é—´: {timestamp} (ç¬¬{frame_num}å¸§)"
                    else:
                        # æ—§æ ¼å¼: åªæœ‰æ—¶é—´æˆ³
                        timestamp = parts[2].replace('-', ':').replace('.jpg', '')
                        label = f"æ—¶é—´: {timestamp}"

                    draw.text((x, y - 25), label, fill='black', font=font)

                except Exception as e:
                    print(f"   âš ï¸  å¤„ç†æˆªå›¾å¤±è´¥: {screenshot_file}, é”™è¯¯: {e}")

            # ä¿å­˜å¯¹æ¯”å›¾
            comparison_path = os.path.join(output_dir, "comparison_evidence.jpg")
            canvas.save(comparison_path, "JPEG", quality=90)

            print(f"   ğŸ“‹ å¯¹æ¯”å›¾å·²ç”Ÿæˆ: {comparison_path}")
            return comparison_path

        except Exception as e:
            print(f"   âŒ ç”Ÿæˆå¯¹æ¯”å›¾å¤±è´¥: {e}")
            return None

    def _cleanup_files(self, files):
        """æ¸…ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        print(f"\nğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        for file in files:
            try:
                genai.delete_file(file.name)
                print(f"   âœ… å·²åˆ é™¤: {file.name}")
            except:
                print(f"   âš ï¸  åˆ é™¤å¤±è´¥: {file.name}")

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='ä½¿ç”¨Gemini APIè¿›è¡Œè§†é¢‘äººç‰©è¯†åˆ«åˆ†æ')
    parser.add_argument('--model', type=str, default='gemini-2.5-pro',
                       help='Geminiæ¨¡å‹åç§° (é»˜è®¤: gemini-2.5-pro)')
    parser.add_argument('--video', type=str, required=True,
                       help='è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--image', type=str, required=True,
                       help='å‚è€ƒå›¾ç‰‡æ–‡ä»¶è·¯å¾„')
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()

    # é…ç½®ä½ çš„APIå¯†é’¥
    API_KEY = "AIzaSyCramKPwcDFmB-6I8Tn6FVioayosJJUeXo"

    # åˆ›å»ºåˆ†æå™¨
    analyzer = GeminiVideoAnalyzer(API_KEY, args.model)

    # åˆ†æè§†é¢‘
    result = analyzer.analyze_person_in_video(
        video_path=args.video,
        reference_photo_path=args.image
    )
    
    if result['success']:
        print(f"\nğŸ‰ åˆ†ææˆåŠŸå®Œæˆï¼")
        # å¯ä»¥è¿›ä¸€æ­¥å¤„ç†åˆ†æç»“æœ
    else:
        print(f"\nğŸ˜ åˆ†æå¤±è´¥: {result['error']}")

if __name__ == "__main__":
    main()